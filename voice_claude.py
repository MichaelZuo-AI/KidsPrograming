#!/usr/bin/env python3
"""Voice Claude - Damiançš„è¯­éŸ³ç¼–ç¨‹åŠ©æ‰‹

æŒ‰ä½ç©ºæ ¼é”®è¯´è¯ï¼Œæ¾å¼€åè‡ªåŠ¨è¯†åˆ«ä¸­æ–‡å¹¶å‘é€ç»™Claude Codeæ‰§è¡Œã€‚
æŒ‰ESCé€€å‡ºç¨‹åºã€‚
"""

import argparse
import os
import subprocess
import sys
import tempfile
import threading
import time

import numpy as np
import sounddevice as sd
import soundfile as sf
from pynput import keyboard

# ANSIé¢œè‰²
RED = "\033[91m"
GREEN = "\033[92m"
YELLOW = "\033[93m"
BLUE = "\033[94m"
CYAN = "\033[96m"
BOLD = "\033[1m"
DIM = "\033[2m"
RESET = "\033[0m"

# å½•éŸ³å‚æ•°
SAMPLE_RATE = 16000
CHANNELS = 1
MIN_DURATION = 0.5  # æœ€çŸ­å½•éŸ³ç§’æ•°


class VoiceClaude:
    def __init__(self, model_size: str = "medium", test_mode: bool = False):
        self.model_size = model_size
        self.test_mode = test_mode
        self.recording = False
        self.frames: list[np.ndarray] = []
        self.stream = None
        self.record_start_time = 0.0
        self.running = True
        self.processing = False  # æ­£åœ¨å¤„ç†ä¸­ï¼Œä¸æ¥å—æ–°å½•éŸ³
        self.whisper_model = None

    def load_model(self):
        """åŠ è½½Whisperæ¨¡å‹"""
        print(f"\n{YELLOW}â³ æ­£åœ¨åŠ è½½è¯­éŸ³è¯†åˆ«æ¨¡å‹ ({self.model_size})...{RESET}")
        print(f"{DIM}   é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼Œè¯·è€å¿ƒç­‰å¾…{RESET}\n")

        from faster_whisper import WhisperModel

        self.whisper_model = WhisperModel(
            self.model_size,
            device="auto",
            compute_type="auto",
        )
        print(f"{GREEN}âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼{RESET}\n")

    def show_welcome(self):
        """æ˜¾ç¤ºæ¬¢è¿ç•Œé¢"""
        print(f"{BOLD}{CYAN}{'=' * 50}{RESET}")
        print(f"{BOLD}{CYAN}  Voice Claude - Damiançš„è¯­éŸ³ç¼–ç¨‹åŠ©æ‰‹{RESET}")
        print(f"{BOLD}{CYAN}{'=' * 50}{RESET}")
        print()
        print(f"  {BOLD}æŒ‰ä½ç©ºæ ¼é”®{RESET} ğŸ¤ è¯´è¯")
        print(f"  {BOLD}æ¾å¼€ç©ºæ ¼é”®{RESET} ğŸš€ å‘é€ç»™Claude")
        print(f"  {BOLD}æŒ‰ESCé”®{RESET}    ğŸ‘‹ é€€å‡ºç¨‹åº")
        if self.test_mode:
            print(f"\n  {YELLOW}ğŸ“‹ æµ‹è¯•æ¨¡å¼ï¼šåªè½¬æ–‡å­—ï¼Œä¸è°ƒç”¨Claude Code{RESET}")
        print()
        print(f"{DIM}  å‡†å¤‡å¥½äº†ï¼Œå¼€å§‹è¯´è¯å§ï¼{RESET}\n")

    def audio_callback(self, indata, frames_count, time_info, status):
        """å½•éŸ³å›è°ƒï¼ˆåœ¨éŸ³é¢‘çº¿ç¨‹ä¸­è¿è¡Œï¼‰"""
        if self.recording:
            self.frames.append(indata.copy())

    def start_recording(self):
        """å¼€å§‹å½•éŸ³"""
        if self.processing:
            return
        self.frames = []
        self.recording = True
        self.record_start_time = time.time()
        self.stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype="float32",
            callback=self.audio_callback,
        )
        self.stream.start()
        print(f"\r  ğŸ”´ {RED}å½•éŸ³ä¸­...{RESET}  ", end="", flush=True)

    def stop_recording(self) -> str | None:
        """åœæ­¢å½•éŸ³ï¼Œè¿”å›ä¸´æ—¶wavæ–‡ä»¶è·¯å¾„"""
        if not self.recording:
            return None

        self.recording = False
        if self.stream:
            self.stream.stop()
            self.stream.close()
            self.stream = None

        duration = time.time() - self.record_start_time

        if duration < MIN_DURATION or not self.frames:
            print(f"\r  {DIM}â­ï¸  å½•éŸ³å¤ªçŸ­ï¼Œå·²è·³è¿‡{RESET}          ")
            return None

        audio_data = np.concatenate(self.frames, axis=0)

        # æ£€æŸ¥æ˜¯å¦åŸºæœ¬æ˜¯é™éŸ³
        if np.abs(audio_data).mean() < 0.005:
            print(f"\r  {DIM}ğŸ”‡ æœªæ£€æµ‹åˆ°å£°éŸ³ï¼Œå·²è·³è¿‡{RESET}          ")
            return None

        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        tmp = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        sf.write(tmp.name, audio_data, SAMPLE_RATE)
        tmp.close()

        print(f"\r  ğŸŸ¢ {GREEN}è¯†åˆ«ä¸­... ({duration:.1f}ç§’å½•éŸ³){RESET}  ", end="", flush=True)
        return tmp.name

    def transcribe(self, wav_path: str) -> str:
        """ç”¨Whisperè¯†åˆ«éŸ³é¢‘"""
        segments, info = self.whisper_model.transcribe(
            wav_path,
            language="zh",
            vad_filter=True,
            beam_size=5,
        )
        text = "".join(seg.text for seg in segments).strip()
        return text

    def call_claude(self, text: str):
        """è°ƒç”¨Claude Codeæ‰§è¡Œå‘½ä»¤"""
        print(f"\n  {BLUE}ğŸ¤– å‘é€ç»™Claude Code...{RESET}\n")
        print(f"{DIM}{'â”€' * 50}{RESET}")

        try:
            result = subprocess.run(
                ["claude", "-p", text],
                capture_output=False,
                text=True,
            )
            if result.returncode != 0:
                print(f"\n  {RED}âŒ Claude Codeè¿”å›é”™è¯¯ (code={result.returncode}){RESET}")
        except FileNotFoundError:
            print(f"\n  {RED}âŒ æ‰¾ä¸åˆ°claudeå‘½ä»¤ï¼Œè¯·ç¡®è®¤Claude Codeå·²å®‰è£…{RESET}")
            print(f"  {DIM}å®‰è£…æ–¹æ³•: npm install -g @anthropic-ai/claude-code{RESET}")

        print(f"{DIM}{'â”€' * 50}{RESET}\n")

    def process_recording(self):
        """å¤„ç†ä¸€æ¬¡å½•éŸ³ï¼šè¯†åˆ« + è°ƒç”¨Claude"""
        self.processing = True
        try:
            wav_path = self.stop_recording()
            if not wav_path:
                return

            try:
                text = self.transcribe(wav_path)
            finally:
                os.unlink(wav_path)

            if not text:
                print(f"\r  {DIM}ğŸ”‡ æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹{RESET}          \n")
                return

            print(f"\r  ğŸ“ {BOLD}è¯†åˆ«ç»“æœï¼š{RESET}{text}          \n")

            if self.test_mode:
                print(f"  {YELLOW}ğŸ“‹ æµ‹è¯•æ¨¡å¼ï¼Œè·³è¿‡Claude Codeè°ƒç”¨{RESET}\n")
            else:
                self.call_claude(text)

            print(f"  {DIM}å‡†å¤‡å¥½äº†ï¼Œç»§ç»­è¯´è¯å§ï¼{RESET}\n")
        finally:
            self.processing = False

    def on_press(self, key):
        """æŒ‰é”®æŒ‰ä¸‹äº‹ä»¶"""
        if key == keyboard.Key.space and not self.recording and not self.processing:
            self.start_recording()
        elif key == keyboard.Key.esc:
            self.running = False
            if self.recording:
                self.recording = False
                if self.stream:
                    self.stream.stop()
                    self.stream.close()
            return False  # åœæ­¢ç›‘å¬

    def on_release(self, key):
        """æŒ‰é”®æ¾å¼€äº‹ä»¶"""
        if key == keyboard.Key.space and self.recording:
            # åœ¨æ–°çº¿ç¨‹ä¸­å¤„ç†ï¼Œé¿å…é˜»å¡é”®ç›˜ç›‘å¬
            threading.Thread(target=self.process_recording, daemon=True).start()

    def run(self):
        """ä¸»å¾ªç¯"""
        self.load_model()
        self.show_welcome()

        with keyboard.Listener(
            on_press=self.on_press,
            on_release=self.on_release,
        ) as listener:
            listener.join()

        print(f"\n{CYAN}ğŸ‘‹ å†è§ï¼ŒDamianï¼ä¸‹æ¬¡å†æ¥ç¼–ç¨‹å§ï¼{RESET}\n")


def main():
    parser = argparse.ArgumentParser(description="Voice Claude - Damiançš„è¯­éŸ³ç¼–ç¨‹åŠ©æ‰‹")
    parser.add_argument(
        "--model",
        default="medium",
        help="Whisperæ¨¡å‹å¤§å° (é»˜è®¤: medium, å¯é€‰: large-v3)",
    )
    parser.add_argument(
        "--test",
        action="store_true",
        help="æµ‹è¯•æ¨¡å¼ï¼Œåªè½¬æ–‡å­—ä¸è°ƒç”¨Claude Code",
    )
    args = parser.parse_args()

    app = VoiceClaude(model_size=args.model, test_mode=args.test)

    try:
        app.run()
    except KeyboardInterrupt:
        print(f"\n\n{CYAN}ğŸ‘‹ å†è§ï¼{RESET}\n")


if __name__ == "__main__":
    main()
